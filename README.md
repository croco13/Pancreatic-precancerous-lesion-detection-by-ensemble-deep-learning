# Pancreatic-precancerous-lesion-detection-by-ensemble-deep-learning
The objective of this project is to develop an AI application that utilizes deep learning  algorithms to accurately identify intraductal papillary mucinous neoplasm (IPMN) from  microscopic images.

Data Preparation for Binary Segmentation (2 Classes)
To prepare the data before training the segmentation models, several steps are necessary. First, essential libraries are imported, including PyTorch for data processing and model training, torchvision for image manipulation, NumPy for matrix calculations, and matplotlib for visualization. The working environment is then verified by checking the versions of PyTorch and torchvision, as well as the availability of a GPU to accelerate training. The paths to the data (images and masks) are defined, and the classes for binary segmentation, along with the color mappings associated with each class, are established. The directory structure is explored to ensure that the data is properly organized, followed by visualizing samples of images and masks to confirm correct loading.

The segmentation masks, initially in RGB format, are converted into a single-channel semantic format to make them compatible with the segmentation models. A custom class, MyDataset, is created to load the images and masks and implement the necessary functions to make these data indexable and usable by the models. Various transformations are applied for data preprocessing and augmentation, including converting images into tensors, resizing, and normalization. These transformations differ for the training and validation sets to improve the model's performance. DataLoaders are created to load the training, validation, and test sets, with specific parameters such as batch size and data shuffling.

Once the data is properly prepared, the segmentation model must be loaded. Several segmentation models are provided, each with its own characteristics and advantages for the binary segmentation task, such as Attention-UNet, DeepLabV3, SegResNet and Ensemble methods. After choosing and loading the segmentation model, it is sent to the appropriate device (GPU or CPU) for training and inference. The code execution begins by setting the model to evaluation mode and predicting a sample segmented mask, followed by visualizing the segmentation results using libraries like Matplotlib.

The model training is managed by a custom function, train_model, which uses the training data loader, loss function, optimizer, and device (GPU or CPU). At each epoch, the training loss is calculated and updated. Model evaluation is performed using the evaluate_model function, which calculates various metrics, such as Intersection over Union (IoU), accuracy, and F1 score, to measure the model's performance on the validation set. A complete training loop, defined in train_loop, trains the model, evaluates its performance, and stores losses and metrics for tracking progress over time.

The nn.CrossEntropyLoss loss function is used for the multi-class segmentation problem, and the Adam optimizer is configured for updating the model weights with an initial learning rate (lr=1e-6). Once all these steps are completed, the code is ready to be executed as a complete script to train the segmentation model on your data, ensuring that the model and data are correctly configured before starting the training process.
